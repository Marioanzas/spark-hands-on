{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "   <img src=\"spark-ml.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SparkML\n",
    "In this notebook, we'll use Spark for:\n",
    "\n",
    "* Sentiment Analysis\n",
    "* Natural Language Processing (NLP)\n",
    "* Decision Trees\n",
    "\n",
    "We will be using a dataset of roughly 50,000 IMDB reviews, which includes the English language text of that review and the rating associated with it (1-10). Based on the text of the review, we want to predict if the rating is \"positive\" or \"negative\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load libraries and foundry utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Plot\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Foundry\n",
    "import foundrywrapper\n",
    "from foundrywrapper import FoundryWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p>\n",
       "<b>Foundry-Wrapper</b> v0.3.3</br>\n",
       "Welcome JEREMY PIRARD  (PIRARD_J)<br>\n",
       "Using <a href='https://core.skywise.com/'>core.skywise.com</a>\n",
       "</p>"
      ],
      "text/plain": [
       "Foundry-Wrapper v0.3.3\n",
       "Welcome JEREMY PIRARD (PIRARD_J)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Required for foundry, not useful for spark purposes\n",
    "fw = FoundryWrapper()\n",
    "fw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (SparkSession.builder \n",
    "        .master('spark://spark-master:7077') #master node URL\n",
    "        .appName('~ Spark hands-on: Spark-ML ~') #my App name\n",
    "        .config('spark.driver.memory', '1g') # memory allocated to the master\n",
    "        .config('spark.driver.cores', '2') # CPU's allocated to the master\n",
    "        .config('spark.executor.instances', '2') # how many executors\n",
    "        .config('spark.executor.memory', '4g') # memory per executor (where the data is stored)\n",
    "        .config('spark.executor.cores', '2') #CPU's per executor\n",
    "        .config(conf=fw.spark.get_spark_app_config())\n",
    "        .getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "65.8 MB, 1 file(s)"
      ],
      "text/plain": [
       "{'sizeInBytes': 65834871, 'numFiles': 1, 'hiddenFilesSizeInBytes': 0, 'numHiddenFiles': 0, 'numTransactions': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Foundry stuff\n",
    "file_rid = fw.compass.get_rid('/Airbus/EY - Zero AOG/ATARI/Spark Hands-on/IMDB_reviews')\n",
    "fw.catalog.get_dataset_view_stats(file_rid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsDF = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(fw.spark.foundryfs_uri(file_rid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic exploration\n",
    "\n",
    "The dataset is a toy one and not that large, let's register it into a SQL view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsDF.createOrReplaceTempView(\"reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviewsDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|              review|rating|\n",
      "+--------------------+------+\n",
      "|It's hard to imag...|   9.0|\n",
      "|Two of Hollywood'...|  10.0|\n",
      "|I saw this film w...|   3.0|\n",
      "|you have loved Th...|  10.0|\n",
      "|I hated the way M...|   1.0|\n",
      "|The first and onl...|  10.0|\n",
      "|This movie is tol...|   4.0|\n",
      "|Unfortunately, th...|   1.0|\n",
      "|I hope we never b...|  10.0|\n",
      "|I managed to tape...|  10.0|\n",
      "|for a lot of time...|   4.0|\n",
      "|This is a delirio...|   7.0|\n",
      "|This is an 'antho...|   4.0|\n",
      "|This is just what...|   1.0|\n",
      "|** out of **** st...|   4.0|\n",
      "|A dying Kung Fu m...|   7.0|\n",
      "|An uptight voyeur...|   4.0|\n",
      "|Being a freshman ...|   9.0|\n",
      "|Lensman is a rath...|   8.0|\n",
      "|Quite what the pr...|   2.0|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviewsDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have two columns, the target that we will predict (*rating*) and the review column which is text data. To create a predictive model we will need to create some variables out of this text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a review look like ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review=\"It's hard to imagine a director capable of such godawful crap as 'Notting Hill' pulling off something as sensitive and as attractive as this, but well, here's the evidence and it's quite compelling. Several have alluded to TV drama, and yes, this does have a seventies Play for Today feel at times, but is always a cut above, mainly I think owing to some quite superlative acting from Anne Reid and to a fine script which shadow-boxes with cliché without ever getting one on the nose, except maybe right at the end. (I didn't like either the tracking shot of indifferent goodbyes through the hallway, nor the oh-what-a-beautiful-morning final scene: she deserved a more studied finale than that I think, after all that hard work. The slippers business was a bit OTT too, on reflection).<br /><br />What I mean about avoiding cliché: well, I for one had a sinking expectation that the 'mature' man May's daughter tries to set her up with would be cast in 2 dimensions as a repulsive old bore, so as to point the contrast more painfully with the attractive, virile young geezer he is unwittingly competing with. Instead, we get an unexpectedly subtle and sympathetic cameo of a lonely, clumsy, not entirely unlikeable and very human fellow, who nevertheless doesn't have much of a clue about entertaining a woman. It was around that point I started to sit up and pay more attention. Here was a script that let the actors breathe and do something interesting with fairly minor parts. Almost Mike Leigh in that respect (minus the contrived catharses that the latter inexplicably goes in for).<br /><br />And of course I was, as everyone probably was, dumbfounded by what Anne Reid does with her character and with her body. She's /not/ 'the repressed, dutiful housewife discovering herself for the first time', this is far too simplistic for the character we have. Again and again there are allusions to her having been a 'bad housewife', not to mention that thing she does with trays, trying to look nurturing and comely and only succeeding in looking awkward. The daughter accuses her of having 'sat in front of the TV all day' instead of, well, whatever her motherly duties might be presumed to have been: she has no answer. She never was a model wife and mother, at least not to herself - that's where a lot of the poignancy comes from, the sense of someone having wasted a life trying to fulfil a role she simply wasn't good at, ever.\", rating=9.0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsDF.take(1) # Recall this is an action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the distribution of scores look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+\n",
      "|count(rating)|rating|\n",
      "+-------------+------+\n",
      "|        10120|   1.0|\n",
      "|         4586|   2.0|\n",
      "|         4961|   3.0|\n",
      "|         5331|   4.0|\n",
      "|         4802|   7.0|\n",
      "|         5858|   8.0|\n",
      "|         4606|   9.0|\n",
      "|         9730|  10.0|\n",
      "+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT count(rating) , rating  FROM reviews GROUP BY rating ORDER BY rating\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the same as :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|rating|count(rating)|\n",
      "+------+-------------+\n",
      "|   1.0|        10120|\n",
      "|   2.0|         4586|\n",
      "|   3.0|         4961|\n",
      "|   4.0|         5331|\n",
      "|   7.0|         4802|\n",
      "|   8.0|         5858|\n",
      "|   9.0|         4606|\n",
      "|  10.0|         9730|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from  pyspark.sql.functions import *\n",
    "reviewsDF.select(\"rating\", \"rating\").groupBy(\"rating\").agg(count(\"rating\")).orderBy(\"rating\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The authors of this dataset have removed the \"neutral\" ratings, which they defined as a rating of 5 or 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Machine learning workflow using Spark-ML\n",
    "\n",
    "Spark ML is a set of API built on top of DataFrame to provide ML worklfows. It is insipred from scikit-learn library in regular python. It has 3 main concepts:\n",
    "- **Transformers**: Algorithm that transforms a DataFrame into another DataFrame (used for features engineering);\n",
    "- **Estimator**: Algorithm fitted on a DataFrame and producing a Transformer;\n",
    "- **Pipeline**: Chains multiple Transformers and Estimators to create an ML workflow.\n",
    "\n",
    "\n",
    "See [the documentation](https://spark.apache.org/docs/latest/api/python/index.html) to have a comprehensive list of the features from Spark ML.\n",
    "\n",
    "On the schema below, we can see an example of a machine learning workflow illustrating these concepts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"nlp_ml_workflow2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Train Test Split\n",
    "\n",
    "We'll split our data into training and test samples. We will use 80% for training, and the remaining 20% for testing. We set a seed to reproduce the same results (i.e. if you re-run this notebook, you'll get the same results both times)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[review: string, rating: double]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trainDF, testDF) = reviewsDF.randomSplit([0.8, 0.2], seed=42)\n",
    "trainDF.cache() # caching it since it will be used for many feature generation\n",
    "testDF.cache() # Same reason"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's determine our baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 49.96%\n"
     ]
    }
   ],
   "source": [
    "positiveRatings = trainDF.filter(\"rating >= 5\").count()\n",
    "totalRatings = trainDF.count()\n",
    "\n",
    "print(\"Baseline accuracy: {0:.2f}%\".format(positiveRatings/totalRatings*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Generating Transformers and Estimators\n",
    "\n",
    "This is the feature engineering of our model!\n",
    "We will create:\n",
    "- A RegexTokenizer (split a sentence into list of word): transformer\n",
    "- A StopWordsRemover (remove common words (\"I\", \"the\" ...): transformer\n",
    "- A CountVectorize (counts the frequency of each word in a sentence): estimator -> it does not return a DataFrame but features!\n",
    "- A Binarizer (to predict only two class \"negative sentiment\" and \"positive\" sentiment): transformer\n",
    "- A DecisionTreeClassifier, that will use the features from the CountVectorizer to make a prediction: estimator\n",
    "\n",
    "Everything will be wrapped up into a Pipeline object (estimator). When fitted, it will produce a transformer. We will then apply it to the test DataFrame to create a new column corresponding to the prediction of the DecisionTreeClassifier !\n",
    "\n",
    "*Nota*: The quality of the feature engineering is not the purpose of the notebook. we could have used TF_IDF or a better algorithm for getting a better score. Cross-validation and hyperparameter tuning are not covered here but are available in Spark ML (*cf docs*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer: Splitting each sentence into individual term.\n",
    "See https://spark.apache.org/docs/2.2.0/ml-features.html#tokenizer\n",
    "You can use this to remove non alphanumeric characters (commas, dots ...) and to lowercase every word in order to facilitate processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+\n",
      "|              review|rating|              tokens|\n",
      "+--------------------+------+--------------------+\n",
      "|Irwin Allen was g...|   4.0|[irwin, allen, wa...|\n",
      "|I got seriously r...|   1.0|[i, got, seriousl...|\n",
      "|The basic idea be...|   2.0|[the, basic, idea...|\n",
      "|I always tell peo...|  10.0|[i, always, tell,...|\n",
      "|I'm an admirer of...|   8.0|[i, m, an, admire...|\n",
      "+--------------------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer\n",
    "\n",
    "tokenizer = (RegexTokenizer()\n",
    "            .setInputCol(\"review\")\n",
    "            .setOutputCol(\"tokens\")\n",
    "            .setPattern(\"\\\\W+\"))\n",
    "\n",
    "tokenizedDF = tokenizer.transform(reviewsDF)\n",
    "tokenizedDF.limit(5).show() # Look at a few tokenized reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of words that do not contain much information about the sentiment of the review (e.g. `the`, `a`, etc.). Let's remove these uninformative words using `StopWordsRemover`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+--------------------+\n",
      "|              review|rating|              tokens|        stopWordFree|\n",
      "+--------------------+------+--------------------+--------------------+\n",
      "|It's hard to imag...|   9.0|[it, s, hard, to,...|[hard, imagine, d...|\n",
      "|Two of Hollywood'...|  10.0|[two, of, hollywo...|[two, hollywood, ...|\n",
      "|I saw this film w...|   3.0|[i, saw, this, fi...|[saw, film, franc...|\n",
      "|you have loved Th...|  10.0|[you, have, loved...|[loved, shawshank...|\n",
      "|I hated the way M...|   1.0|[i, hated, the, w...|[hated, way, ms, ...|\n",
      "+--------------------+------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "remover = (StopWordsRemover()\n",
    "          .setInputCol(\"tokens\")\n",
    "          .setOutputCol(\"stopWordFree\"))\n",
    "\n",
    "removedStopWordsDF = remover.transform(tokenizedDF)\n",
    "removedStopWordsDF.limit(5).show() # Look at a few tokenized reviews without stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where do the stop words actually come from? Spark includes a small English list as a default, which we're implicitly using here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " 'should',\n",
       " 'now',\n",
       " \"i'll\",\n",
       " \"you'll\",\n",
       " \"he'll\",\n",
       " \"she'll\",\n",
       " \"we'll\",\n",
       " \"they'll\",\n",
       " \"i'd\",\n",
       " \"you'd\",\n",
       " \"he'd\",\n",
       " \"she'd\",\n",
       " \"we'd\",\n",
       " \"they'd\",\n",
       " \"i'm\",\n",
       " \"you're\",\n",
       " \"he's\",\n",
       " \"she's\",\n",
       " \"it's\",\n",
       " \"we're\",\n",
       " \"they're\",\n",
       " \"i've\",\n",
       " \"we've\",\n",
       " \"you've\",\n",
       " \"they've\",\n",
       " \"isn't\",\n",
       " \"aren't\",\n",
       " \"wasn't\",\n",
       " \"weren't\",\n",
       " \"haven't\",\n",
       " \"hasn't\",\n",
       " \"hadn't\",\n",
       " \"don't\",\n",
       " \"doesn't\",\n",
       " \"didn't\",\n",
       " \"won't\",\n",
       " \"wouldn't\",\n",
       " \"shan't\",\n",
       " \"shouldn't\",\n",
       " \"mustn't\",\n",
       " \"can't\",\n",
       " \"couldn't\",\n",
       " 'cannot',\n",
       " 'could',\n",
       " \"here's\",\n",
       " \"how's\",\n",
       " \"let's\",\n",
       " 'ought',\n",
       " \"that's\",\n",
       " \"there's\",\n",
       " \"what's\",\n",
       " \"when's\",\n",
       " \"where's\",\n",
       " \"who's\",\n",
       " \"why's\",\n",
       " 'would']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopWords = remover.getStopWords()\n",
    "stopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the `br` from our reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover.setStopWords([\"br\"] + stopWords)\n",
    "removedStopWordsDF = remover.transform(tokenizedDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply a CountVectorizer model\n",
    "\n",
    "This model maps each sentence to a matrix containing each count of the words defined by the whole vocabulary of the corpus.\n",
    "\n",
    "For instance\n",
    "\n",
    " id | texts\n",
    "----|----------\n",
    " 0  | Array(\"a\", \"b\", \"c\")\n",
    " 1  | Array(\"a\", \"b\", \"b\", \"c\", \"a\")\n",
    " \n",
    " maps to:\n",
    " \n",
    "  id | texts                           | vector\n",
    "----|---------------------------------|---------------\n",
    " 0  | Array(\"a\", \"b\", \"c\")            | (3,[0,1,2],[1.0,1.0,1.0])\n",
    " 1  | Array(\"a\", \"b\", \"b\", \"c\", \"a\")  | (3,[0,1,2],[2.0,2.0,1.0])\n",
    " \n",
    " This means that there are two times the word \"a\" , \"b\" and one time the word \"c\" in the second sentence.\n",
    " \n",
    " This produces a good representation to feed a classification algorithm.\n",
    " \n",
    " Nota: Setting the vocabulary size forces the model to select the most frequent words in the given corpus. This reduce the dimension of the features engineered data.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "counts = (CountVectorizer()\n",
    "          .setInputCol(\"stopWordFree\")\n",
    "          .setOutputCol(\"features\")\n",
    "          .setVocabSize(1000))\n",
    "\n",
    "countModel = counts.fit(removedStopWordsDF) # It's a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Now let's adjust the label (target) values__\n",
    "\n",
    "We want to group the reviews into \"positive\" or \"negative\" sentiment. So all of the star \"levels\" need to be collapsed into one of two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Binarizer\n",
    "\n",
    "binarizer = (Binarizer()\n",
    "            .setInputCol(\"rating\")\n",
    "            .setOutputCol(\"label\")\n",
    "            .setThreshold(5.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to use a Decision Tree model to fit to our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "pipeline = Pipeline().setStages([tokenizer, remover, counts, binarizer, dtc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel = pipeline.fit(trainDF)\n",
    "decisionTree = pipelineModel.stages[-1] #We can retrieve a particular step of our pipeline like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_2d7d2f1857bc) of depth 5 with 55 nodes\n",
      "  If (feature 13 <= 0.5)\n",
      "   If (feature 141 <= 0.5)\n",
      "    If (feature 341 <= 0.5)\n",
      "     If (feature 15 <= 0.5)\n",
      "      If (feature 262 <= 0.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 262 > 0.5)\n",
      "       Predict: 0.0\n",
      "     Else (feature 15 > 0.5)\n",
      "      If (feature 262 <= 0.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 262 > 0.5)\n",
      "       Predict: 0.0\n",
      "    Else (feature 341 > 0.5)\n",
      "     If (feature 782 <= 1.5)\n",
      "      If (feature 634 <= 1.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 634 > 1.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 782 > 1.5)\n",
      "      Predict: 1.0\n",
      "   Else (feature 141 > 0.5)\n",
      "    If (feature 35 <= 0.5)\n",
      "     If (feature 39 <= 0.5)\n",
      "      Predict: 0.0\n",
      "     Else (feature 39 > 0.5)\n",
      "      If (feature 32 <= 3.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 32 > 3.5)\n",
      "       Predict: 1.0\n",
      "    Else (feature 35 > 0.5)\n",
      "     If (feature 191 <= 1.5)\n",
      "      Predict: 0.0\n",
      "     Else (feature 191 > 1.5)\n",
      "      If (feature 18 <= 2.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 18 > 2.5)\n",
      "       Predict: 0.0\n",
      "  Else (feature 13 > 0.5)\n",
      "   If (feature 15 <= 0.5)\n",
      "    If (feature 141 <= 0.5)\n",
      "     If (feature 209 <= 0.5)\n",
      "      Predict: 0.0\n",
      "     Else (feature 209 > 0.5)\n",
      "      If (feature 13 <= 1.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 13 > 1.5)\n",
      "       Predict: 0.0\n",
      "    Else (feature 141 > 0.5)\n",
      "     If (feature 582 <= 1.5)\n",
      "      If (feature 573 <= 1.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 573 > 1.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 582 > 1.5)\n",
      "      If (feature 1 <= 1.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 1 > 1.5)\n",
      "       Predict: 1.0\n",
      "   Else (feature 15 > 0.5)\n",
      "    If (feature 141 <= 0.5)\n",
      "     If (feature 13 <= 1.5)\n",
      "      If (feature 15 <= 1.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 15 > 1.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 13 > 1.5)\n",
      "      If (feature 576 <= 0.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 576 > 0.5)\n",
      "       Predict: 1.0\n",
      "    Else (feature 141 > 0.5)\n",
      "     If (feature 282 <= 0.5)\n",
      "      If (feature 802 <= 0.5)\n",
      "       Predict: 0.0\n",
      "      Else (feature 802 > 0.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 282 > 0.5)\n",
      "      If (feature 20 <= 0.5)\n",
      "       Predict: 1.0\n",
      "      Else (feature 20 > 0.5)\n",
      "       Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(decisionTree.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the pipeline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to add foundry stuff\n",
    "\n",
    "# fileName = \"/tmp/DT_Pipeline\"\n",
    "# pipelineModel.write().overwrite().save(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml import PipelineModel\n",
    "# # Load saved model\n",
    "# savedPipelineModel = PipelineModel.load(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultDF = savedPipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall a prediction of 1 (resp. 0) maps to a positive (resp. negative) sentiment (rating > 5 or rating < 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+--------------------+--------------------+-----+----------------+--------------------+----------+\n",
      "|              review|rating|              tokens|        stopWordFree|            features|label|   rawPrediction|         probability|prediction|\n",
      "+--------------------+------+--------------------+--------------------+--------------------+-----+----------------+--------------------+----------+\n",
      "|!!!! MILD SPOILER...|   4.0|[mild, spoilers, ...|[mild, spoilers, ...|(1000,[0,3,4,7,11...|  0.0|[7987.0,11496.0]|[0.40994713339834...|       1.0|\n",
      "|!!!! MILD SPOILER...|   4.0|[mild, spoilers, ...|[mild, spoilers, ...|(1000,[0,1,2,3,4,...|  0.0| [4419.0,1247.0]|[0.77991528415107...|       0.0|\n",
      "|!!!!! OF COURSE T...|   4.0|[of, course, ther...|[course, spoilers...|(1000,[1,2,9,11,1...|  0.0| [4419.0,1247.0]|[0.77991528415107...|       0.0|\n",
      "|'2001: A Space Od...|   7.0|[2001, a, space, ...|[2001, space, ody...|(1000,[1,2,3,5,6,...|  1.0|[7987.0,11496.0]|[0.40994713339834...|       1.0|\n",
      "|'A Cry in the Dar...|   8.0|[a, cry, in, the,...|[cry, dark, maste...|(1000,[2,7,16,29,...|  1.0|[7987.0,11496.0]|[0.40994713339834...|       1.0|\n",
      "|'After World War ...|   2.0|[after, world, wa...|[world, war, expe...|(1000,[1,2,3,4,8,...|  0.0|[7987.0,11496.0]|[0.40994713339834...|       1.0|\n",
      "|'Ardh Satya' is o...|   8.0|[ardh, satya, is,...|[ardh, satya, one...|(1000,[1,2,6,7,15...|  1.0| [1546.0,5633.0]|[0.21535032734364...|       1.0|\n",
      "|'Are You in the H...|   7.0|[are, you, in, th...|[house, alone, be...|(1000,[1,2,3,8,10...|  1.0|[7987.0,11496.0]|[0.40994713339834...|       1.0|\n",
      "|'Atlantis: The Lo...|   8.0|[atlantis, the, l...|[atlantis, lost, ...|(1000,[0,1,2,3,4,...|  1.0|    [60.0,128.0]|[0.31914893617021...|       1.0|\n",
      "|'Baptists at Our ...|   1.0|[baptists, at, ou...|[baptists, barbec...|(1000,[0,1,2,3,4,...|  0.0|   [377.0,140.0]|[0.72920696324951...|       0.0|\n",
      "|'Before the devil...|   8.0|[before, the, dev...|[devil, knows, re...|(1000,[2,5,7,21,2...|  1.0|[7987.0,11496.0]|[0.40994713339834...|       1.0|\n",
      "|'Boom' has garner...|   1.0|[boom, has, garne...|[boom, garnered, ...|(1000,[2,4,5,10,1...|  0.0| [4419.0,1247.0]|[0.77991528415107...|       0.0|\n",
      "|'COSBY,' in my op...|   9.0|[cosby, in, my, o...|[cosby, opinion, ...|(1000,[2,3,4,6,8,...|  1.0|[7987.0,11496.0]|[0.40994713339834...|       1.0|\n",
      "|'Capitães de Abri...|  10.0|[capit, es, de, a...|[capit, es, de, a...|(1000,[0,1,2,3,4,...|  1.0| [1546.0,5633.0]|[0.21535032734364...|       1.0|\n",
      "|'Citizen X' tells...|   7.0|[citizen, x, tell...|[citizen, x, tell...|(1000,[1,3,4,6,7,...|  1.0|[7987.0,11496.0]|[0.40994713339834...|       1.0|\n",
      "|'Curse of the For...|   4.0|[curse, of, the, ...|[curse, forty, ni...|(1000,[1,8,17,18,...|  0.0|[7987.0,11496.0]|[0.40994713339834...|       1.0|\n",
      "|'Dead Man Walking...|   9.0|[dead, man, walki...|[dead, man, walki...|(1000,[0,1,2,6,8,...|  1.0| [1546.0,5633.0]|[0.21535032734364...|       1.0|\n",
      "|'Death Wish 3' br...|   8.0|[death, wish, 3, ...|[death, wish, 3, ...|(1000,[0,1,2,3,4,...|  1.0| [4419.0,1247.0]|[0.77991528415107...|       0.0|\n",
      "|'Death Wish 3' is...|   4.0|[death, wish, 3, ...|[death, wish, 3, ...|(1000,[0,3,4,6,12...|  0.0|[7987.0,11496.0]|[0.40994713339834...|       1.0|\n",
      "|'Der Todesking' i...|   7.0|[der, todesking, ...|[der, todesking, ...|(1000,[1,2,3,5,6,...|  1.0| [1546.0,5633.0]|[0.21535032734364...|       1.0|\n",
      "+--------------------+------+--------------------+--------------------+--------------------+-----+----------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultDF = pipelineModel.transform(testDF)\n",
    "resultDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See accuracy of the model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.696548948586377\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Accuracy: %(result)s\" % {\"result\": evaluator.evaluate(resultDF)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if there is a lot of work to do we have improved the accuracy of the model comparing to a baseline ! This could be enhanced by tuning parameter of the model, adding more complex natural language processing features such as [TF-IDF](https://spark.apache.org/docs/2.2.0/ml-features.html#tf-idf), using a larger vocabulary, using n-grams ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|  1.0|       1.0| 4380|\n",
      "|  0.0|       1.0| 2413|\n",
      "|  1.0|       0.0|  603|\n",
      "|  0.0|       0.0| 2543|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultDF.groupBy(\"label\", \"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Go back to regular python code to generate visualization\n",
    "\n",
    "Let's plot a nicer view of our confusion matrix using regular python/pandas/sklearn librairies.\n",
    "\n",
    "Taken from: https://runawayhorse001.github.io/LearningApacheSpark/classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review='!!!! MILD SPOILERS !!!!<br /><br />The premise goes like this : A store gets burnt down and assistant Sergio is asked by the father of the man who started the fire to take the wrap to which Sergio agrees .<br /><br />So far so good , but there`s a fair lapse of logic involved Sergio agrees to do this for the sum of 25,000 dollars but why ? Come on guys if you were a good looking white boy would you run the risk of getting a long spell in a tough jail ( A very real possibilty for arson ) for the sake of 25 grand ? I know I wouldn`t , and seeing as you`d have a criminal record no employer would want to touch you with a barge pole so is $25,000 dollars all that much for a life of workfare and welfare cheques ? There`s also something else that seems to have gone without notice from the premise , since Mister Lumpke has told Sergio that his son did the fire he seems unware of the possibility that he may know too much . Wouldn`t alarm bells be ringing in your mind about someone wanting to keep you quite if they told you something ? <br /><br />I guess we`re not suppossed to think about such details since A PYROMANIAC`S LOVE STORY isn`t suppossed to be an intelligent thriller , it`s a light hearted romantic comedy/ chick flick that`s probably best apprieciated as a girls night in . Looking through this comments page it is obvious that the movie has its defenders but as a cynical male I wasn`t too impressed and William Baldwin does go way over the top', rating=4.0, tokens=['mild', 'spoilers', 'br', 'br', 'the', 'premise', 'goes', 'like', 'this', 'a', 'store', 'gets', 'burnt', 'down', 'and', 'assistant', 'sergio', 'is', 'asked', 'by', 'the', 'father', 'of', 'the', 'man', 'who', 'started', 'the', 'fire', 'to', 'take', 'the', 'wrap', 'to', 'which', 'sergio', 'agrees', 'br', 'br', 'so', 'far', 'so', 'good', 'but', 'there', 's', 'a', 'fair', 'lapse', 'of', 'logic', 'involved', 'sergio', 'agrees', 'to', 'do', 'this', 'for', 'the', 'sum', 'of', '25', '000', 'dollars', 'but', 'why', 'come', 'on', 'guys', 'if', 'you', 'were', 'a', 'good', 'looking', 'white', 'boy', 'would', 'you', 'run', 'the', 'risk', 'of', 'getting', 'a', 'long', 'spell', 'in', 'a', 'tough', 'jail', 'a', 'very', 'real', 'possibilty', 'for', 'arson', 'for', 'the', 'sake', 'of', '25', 'grand', 'i', 'know', 'i', 'wouldn', 't', 'and', 'seeing', 'as', 'you', 'd', 'have', 'a', 'criminal', 'record', 'no', 'employer', 'would', 'want', 'to', 'touch', 'you', 'with', 'a', 'barge', 'pole', 'so', 'is', '25', '000', 'dollars', 'all', 'that', 'much', 'for', 'a', 'life', 'of', 'workfare', 'and', 'welfare', 'cheques', 'there', 's', 'also', 'something', 'else', 'that', 'seems', 'to', 'have', 'gone', 'without', 'notice', 'from', 'the', 'premise', 'since', 'mister', 'lumpke', 'has', 'told', 'sergio', 'that', 'his', 'son', 'did', 'the', 'fire', 'he', 'seems', 'unware', 'of', 'the', 'possibility', 'that', 'he', 'may', 'know', 'too', 'much', 'wouldn', 't', 'alarm', 'bells', 'be', 'ringing', 'in', 'your', 'mind', 'about', 'someone', 'wanting', 'to', 'keep', 'you', 'quite', 'if', 'they', 'told', 'you', 'something', 'br', 'br', 'i', 'guess', 'we', 're', 'not', 'suppossed', 'to', 'think', 'about', 'such', 'details', 'since', 'a', 'pyromaniac', 's', 'love', 'story', 'isn', 't', 'suppossed', 'to', 'be', 'an', 'intelligent', 'thriller', 'it', 's', 'a', 'light', 'hearted', 'romantic', 'comedy', 'chick', 'flick', 'that', 's', 'probably', 'best', 'apprieciated', 'as', 'a', 'girls', 'night', 'in', 'looking', 'through', 'this', 'comments', 'page', 'it', 'is', 'obvious', 'that', 'the', 'movie', 'has', 'its', 'defenders', 'but', 'as', 'a', 'cynical', 'male', 'i', 'wasn', 't', 'too', 'impressed', 'and', 'william', 'baldwin', 'does', 'go', 'way', 'over', 'the', 'top'], stopWordFree=['mild', 'spoilers', 'premise', 'goes', 'like', 'store', 'gets', 'burnt', 'assistant', 'sergio', 'asked', 'father', 'man', 'started', 'fire', 'take', 'wrap', 'sergio', 'agrees', 'far', 'good', 'fair', 'lapse', 'logic', 'involved', 'sergio', 'agrees', 'sum', '25', '000', 'dollars', 'come', 'guys', 'good', 'looking', 'white', 'boy', 'run', 'risk', 'getting', 'long', 'spell', 'tough', 'jail', 'real', 'possibilty', 'arson', 'sake', '25', 'grand', 'know', 'wouldn', 'seeing', 'd', 'criminal', 'record', 'employer', 'want', 'touch', 'barge', 'pole', '25', '000', 'dollars', 'much', 'life', 'workfare', 'welfare', 'cheques', 'also', 'something', 'else', 'seems', 'gone', 'without', 'notice', 'premise', 'since', 'mister', 'lumpke', 'told', 'sergio', 'son', 'fire', 'seems', 'unware', 'possibility', 'may', 'know', 'much', 'wouldn', 'alarm', 'bells', 'ringing', 'mind', 'someone', 'wanting', 'keep', 'quite', 'told', 'something', 'guess', 're', 'suppossed', 'think', 'details', 'since', 'pyromaniac', 'love', 'story', 'isn', 'suppossed', 'intelligent', 'thriller', 'light', 'hearted', 'romantic', 'comedy', 'chick', 'flick', 'probably', 'best', 'apprieciated', 'girls', 'night', 'looking', 'comments', 'page', 'obvious', 'movie', 'defenders', 'cynical', 'male', 'wasn', 'impressed', 'william', 'baldwin', 'go', 'way', 'top'], features=SparseVector(1000, {0: 1.0, 3: 1.0, 4: 2.0, 7: 1.0, 11: 2.0, 16: 1.0, 20: 1.0, 23: 1.0, 30: 1.0, 32: 1.0, 35: 1.0, 37: 2.0, 40: 1.0, 48: 2.0, 50: 1.0, 52: 1.0, 56: 1.0, 78: 1.0, 81: 1.0, 86: 2.0, 89: 1.0, 95: 1.0, 97: 1.0, 99: 1.0, 100: 1.0, 105: 1.0, 106: 1.0, 110: 1.0, 118: 1.0, 121: 1.0, 130: 2.0, 134: 1.0, 151: 2.0, 166: 1.0, 179: 1.0, 188: 1.0, 200: 1.0, 206: 1.0, 214: 1.0, 215: 1.0, 217: 1.0, 233: 1.0, 271: 1.0, 280: 1.0, 287: 1.0, 325: 1.0, 339: 1.0, 354: 1.0, 367: 1.0, 372: 1.0, 381: 1.0, 408: 1.0, 449: 1.0, 452: 2.0, 454: 2.0, 472: 1.0, 530: 1.0, 548: 1.0, 569: 1.0, 622: 1.0, 679: 1.0, 683: 1.0, 732: 2.0, 792: 1.0, 815: 2.0, 869: 1.0, 894: 1.0, 947: 1.0, 977: 1.0}), label=0.0, rawPrediction=DenseVector([7987.0, 11496.0]), probability=DenseVector([0.4099, 0.5901]), prediction=1.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDF.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "class_temp = resultDF.select(\"label\").groupBy(\"label\")\\\n",
    "                        .count().sort('count', ascending=False).toPandas()\n",
    "\n",
    "class_names = class_temp[\"label\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4380,  603],\n",
       "       [2413, 2543]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = resultDF.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = resultDF.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred,labels=class_names)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[4380  603]\n",
      " [2413 2543]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, visualization example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
